
\begin{abstract}
    Weakly supervised object detection is attracting significant attention as it avoids supervision from bounding box annotations, which are expensive and tedious. Exsiting works focus on learning object appearance representation from static images with multiple instance learning (MIL). However, they often fail to generalize to objects in videos because of domain shift. In this work, we investigate the problem of weakly supervised object detection with the supervision from video-level interactive action annotations. We propose to leverage the object appearance and motion consistency to learn the object representation. We conduct experiments on Charades dataset.

    % Different from learning solely from static images, appereance consistency over time can be leveraged in videos. More importantly, the object apperance representation is further regularized by jointly modeling the appereance information with different activity classes which involve the same object category. 
    % We have conducted comprehensive experiments on Charades and (potentially MPII-Cooking) dataset and achieve () performance. To validate the performance of generalization, (the proposed method) is directly tested on (Pascal VOC) dataset and shows superior performance over other baselines.
\end{abstract}
